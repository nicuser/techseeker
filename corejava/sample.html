what is Bigdata ?

    large volume of data - both structured and unstructured

    analyzed for insights that lead to better decisions and strategic business moves.

usecases of bigdata ?

    Fraud Detection and Security
        Prevent fraud by leveraging analytics, machine learning, and Big Data
        technology to gain a holistic view of customers, identify patterns buried in data,
        cluster information, and distinguish fraudulent activity from normal activity.

    Compliance and Regulatory Reporting
        Traders to document everything that goes into each swap trade by
        implementing a deal monitoring system based on a new generation of Big
        Data technology.

    Customer Segmentation
        Group customers into different segments to support sales, promotion, and
        marketing campaigns by collecting and analyzing all available data and using
        Big Data technology to mine for intelligence from underlying data.

    Risk Management
        Support new regulations and increasing demand for better internal
        management support by implementing a central, integrated finance, and risk
        management data platform that can quickly and flexibly address new
        requirements. 

    Personalized Product Offering
        Target new product and service offerings to the right customers by
        implementing software that supports flexible and integrated processes for
        understanding customer buying habits, what channels customers listen to, and
        who the key influencers are.


what is framework ?

how hadoop is different from existing business intelligence tools ?

vertical (CPUs or memory to a single computer) vs horizontal scalability (adding more systems)


===========================================================================================

About Hadoop

    1) an open-source software for reliable, scalable, distributed computing.

    2) allows distributed processing of large data sets across clusters of computers using simple programming models. 

    3) designed to scale up from single servers to thousands of machines, each offering local computation and storage.


About Hadoop modules : 

    Hadoop Common: The common utilities that support the other Hadoop modules.

    Hadoop Distributed File System (HDFSâ„¢): A distributed file system that provides high-throughput access to application data.

    Hadoop YARN: A framework for job scheduling and cluster resource management.

    Hadoop MapReduce: A YARN-based system for parallel processing of large data sets.


Hadoop-related projects :

    Avro: A data serialization system.

    Cassandra: A scalable multi-master database with no single points of failure.

    HBase: A scalable, distributed database that supports structured data storage for large tables.

    Hive: A data warehouse infrastructure that provides data summarization and ad hoc querying.

    Pig: A high-level data-flow language and execution framework for parallel computation.

    ZooKeeper: A high-performance coordination service for distributed applications.

    OOZIE : Oozie is a workflow scheduler system to manage Apache Hadoop jobs.


===========================================================================================

introduction to data

introduction to metadata

introduction to various data sources

introduction to data formats xml/json/csv

introduction to data schema xsd, table creation etc ...


===========================================================================================

what is a protocol ?

introduction to protocols ?

introduction to synchronous/asynchronous protocols 


===========================================================================================

what is network ?

what is node ?

what is cluster ?

what is a data center ?

===========================================================================================

what is one tier architecture ?

what is two tier architecture ?

what is three tier architecture ?

what is n-tier architecture ?


===========================================================================================

introduction to distributed applications

challenges in distributed applications 

importance of serialization

===========================================================================================

introduction to java

what is jvm ?

what is JRE ?

java execution phases ?

HelloWorld

compile and run from command line (have the sample code /Users/myhome/bigdata/javaDemo/stand-alone)

down load netbeans

compile and run from IDE

sample maven project

show how maven automates what we done manually

introduction to oops

calculator example (vedic and regular calculations)

introduction to java keywords; if, for, while etc ...

introduction to common API's JAXB, JDBC, JMS, JAX-RS, JAX-WS, JNDI

what is framework ?

introduction about Spring, Struts, guice, Primefaces etc ...

introduction to serialization with example (/Users/myhome/Downloads/convergent/corejava)

===========================================================================================

introduction to github

demo on github

. create branch
. code review
. merge the code

===========================================================================================

introduction to unix

how to copy files
    cp filename destination

how to login to remote box
    ssh username@remoteipaddress

creating ssh key
    ssh-keygen

grep command
    grep "search-string" filename
    Case insensitive search using grep -i (ex: grep -i "string" FILE)
    Match regular expression in files (ex: grep "lines.*empty" demo_file)
    
    reference : http://www.thegeekstuff.com/2009/03/15-practical-unix-grep-command-examples/

curl command

wget command

cat

vi editor

scp command

rm command

ps command
    To see every process on	the system (ex: ps -e)
    To see every process running as	root (ex: ps -U root -u root u)
    To get security	info (ex: ps -eo euser,ruser,suser,fuser,f,comm,label)

    ps -U hbase -u hbase u
    ps -U hdfs -u hdfs u
    http://www.freebsd.org/cgi/man.cgi?query=ps&manpath=SuSE+Linux/i386+11.3

netstat
    netstat -pln (What processes are using which ports on unix)

===========================================================================================

setting up hadoop

login into hadoop

hive console

list the services running

hdfs commands

sqoop introduction

setting up mysql


===========================================================================================

exercise

===========================================================================================

introcution to jdbc

introduction to driver

importing data from sqoop

. copying the driver into hadoop class path
. monitoring the job
. listing the jobs running from command line
. killing the job running
. running the job

introduction to HDFS

browse the data imported into HDFS from HIVE

removing the data from HDFS

